{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5e7a07-109a-4ec6-b42a-3d012aff414b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab19dde-f063-4f8e-95c9-fa6d306d1b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "WARNING:root:The OGB package is out of date. Your version is 1.3.4, while the latest version is 1.3.5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "class split information: (tensor([3, 2]), tensor([6, 1]), tensor([4, 0]))\n",
      "task_id: 0 Epoch #0: train_acc: 0.475 val_acc: 0.6695 train_loss: 0.7137 val_loss: 0.6913\n",
      "task_id: 0 Epoch #10: train_acc: 1.0 val_acc: 0.7076 train_loss: 0.0017 val_loss: 0.659\n",
      "task_id: 0 Epoch #20: train_acc: 1.0 val_acc: 0.6864 train_loss: 0.0002 val_loss: 0.607\n",
      "task_id: 0 Epoch #30: train_acc: 1.0 val_acc: 0.6992 train_loss: 0.0001 val_loss: 0.5602\n",
      "task_id: 0 Epoch #40: train_acc: 1.0 val_acc: 0.7712 train_loss: 0.0001 val_loss: 0.5071\n",
      "task_id: 0 Epoch #50: train_acc: 1.0 val_acc: 0.9025 train_loss: 0.0 val_loss: 0.432\n",
      "task_id: 0 Epoch #60: train_acc: 1.0 val_acc: 0.9746 train_loss: 0.0 val_loss: 0.3352\n",
      "task_id: 0 Epoch #70: train_acc: 1.0 val_acc: 0.9661 train_loss: 0.0 val_loss: 0.243\n",
      "task_id: 0 Epoch #80: train_acc: 1.0 val_acc: 0.9492 train_loss: 0.0 val_loss: 0.1876\n",
      "task_id: 0 Epoch #90: train_acc: 1.0 val_acc: 0.9407 train_loss: 0.0 val_loss: 0.1674\n",
      "task_id: 0 Epoch #100: train_acc: 1.0 val_acc: 0.9407 train_loss: 0.0 val_loss: 0.1612\n",
      "task_id: 0 Epoch #110: train_acc: 1.0 val_acc: 0.9364 train_loss: 0.0 val_loss: 0.1611\n",
      "task_id: 0 Epoch #120: train_acc: 1.0 val_acc: 0.9364 train_loss: 0.0 val_loss: 0.162\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-04.\n",
      "task_id: 0 Epoch #130: train_acc: 1.0 val_acc: 0.9364 train_loss: 0.0 val_loss: 0.1624\n",
      "task_id: 0 Epoch #140: train_acc: 1.0 val_acc: 0.9364 train_loss: 0.0 val_loss: 0.1624\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-05.\n",
      "task_id: 0 Epoch #150: train_acc: 1.0 val_acc: 0.9364 train_loss: 0.0 val_loss: 0.1624\n",
      "task_id: 0 Epoch #160: train_acc: 1.0 val_acc: 0.9364 train_loss: 0.0 val_loss: 0.1624\n",
      "Epoch   168: reducing learning rate of group 0 to 2.0000e-06.\n",
      "task_id: 1 Epoch #0: train_acc: 0.025 val_acc: 0.2 train_loss: 1.6893 val_loss: 1.4779\n",
      "task_id: 1 Epoch #10: train_acc: 1.0 val_acc: 0.9231 train_loss: 0.0035 val_loss: 0.3364\n",
      "task_id: 1 Epoch #20: train_acc: 1.0 val_acc: 0.9231 train_loss: 0.0002 val_loss: 0.2056\n",
      "task_id: 1 Epoch #30: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0001 val_loss: 0.1754\n",
      "task_id: 1 Epoch #40: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1621\n",
      "task_id: 1 Epoch #50: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.156\n",
      "task_id: 1 Epoch #60: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1533\n",
      "task_id: 1 Epoch #70: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.152\n",
      "task_id: 1 Epoch #80: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1515\n",
      "task_id: 1 Epoch #90: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1512\n",
      "task_id: 1 Epoch #100: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.151\n",
      "task_id: 1 Epoch #110: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1509\n",
      "task_id: 1 Epoch #120: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1508\n",
      "task_id: 1 Epoch #130: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1507\n",
      "task_id: 1 Epoch #140: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1507\n",
      "task_id: 1 Epoch #150: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1506\n",
      "task_id: 1 Epoch #160: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1505\n",
      "task_id: 1 Epoch #170: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1505\n",
      "task_id: 1 Epoch #180: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1504\n",
      "task_id: 1 Epoch #190: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1504\n",
      "task_id: 1 Epoch #200: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1503\n",
      "task_id: 1 Epoch #210: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1503\n",
      "task_id: 1 Epoch #220: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1502\n",
      "task_id: 1 Epoch #230: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1502\n",
      "task_id: 1 Epoch #240: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1501\n",
      "task_id: 1 Epoch #250: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1501\n",
      "task_id: 1 Epoch #260: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1501\n",
      "task_id: 1 Epoch #270: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.15\n",
      "task_id: 1 Epoch #280: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.15\n",
      "task_id: 1 Epoch #290: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.15\n",
      "task_id: 1 Epoch #300: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1499\n",
      "task_id: 1 Epoch #310: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1499\n",
      "task_id: 1 Epoch #320: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1499\n",
      "task_id: 1 Epoch #330: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1499\n",
      "task_id: 1 Epoch #340: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1499\n",
      "task_id: 1 Epoch #350: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1498\n",
      "task_id: 1 Epoch #360: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1498\n",
      "task_id: 1 Epoch #370: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1498\n",
      "task_id: 1 Epoch #380: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1498\n",
      "task_id: 1 Epoch #390: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1497\n",
      "task_id: 1 Epoch #400: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1497\n",
      "task_id: 1 Epoch #410: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1497\n",
      "task_id: 1 Epoch #420: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1497\n",
      "task_id: 1 Epoch #430: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1497\n",
      "task_id: 1 Epoch #440: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1497\n",
      "task_id: 1 Epoch #450: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1497\n",
      "Epoch   456: reducing learning rate of group 0 to 1.0000e-04.\n",
      "task_id: 1 Epoch #460: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1497\n",
      "task_id: 1 Epoch #470: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1497\n",
      "Epoch   477: reducing learning rate of group 0 to 1.0000e-05.\n",
      "task_id: 1 Epoch #480: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1497\n",
      "task_id: 1 Epoch #490: train_acc: 1.0 val_acc: 0.9538 train_loss: 0.0 val_loss: 0.1498\n",
      "Epoch   498: reducing learning rate of group 0 to 2.0000e-06.\n",
      "task_id: 2 Epoch #0: train_acc: 0.0 val_acc: 0.0211 train_loss: 2.4776 val_loss: 2.2951\n",
      "task_id: 2 Epoch #10: train_acc: 1.0 val_acc: 0.6831 train_loss: 0.0508 val_loss: 0.9146\n",
      "task_id: 2 Epoch #20: train_acc: 1.0 val_acc: 0.8521 train_loss: 0.0026 val_loss: 0.5543\n",
      "task_id: 2 Epoch #30: train_acc: 1.0 val_acc: 0.8944 train_loss: 0.0004 val_loss: 0.4792\n",
      "task_id: 2 Epoch #40: train_acc: 1.0 val_acc: 0.9014 train_loss: 0.0002 val_loss: 0.4583\n",
      "task_id: 2 Epoch #50: train_acc: 1.0 val_acc: 0.9085 train_loss: 0.0001 val_loss: 0.4516\n",
      "task_id: 2 Epoch #60: train_acc: 1.0 val_acc: 0.9155 train_loss: 0.0001 val_loss: 0.4501\n",
      "task_id: 2 Epoch #70: train_acc: 1.0 val_acc: 0.9155 train_loss: 0.0001 val_loss: 0.4508\n",
      "task_id: 2 Epoch #80: train_acc: 1.0 val_acc: 0.9155 train_loss: 0.0001 val_loss: 0.4525\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "task_id: 2 Epoch #90: train_acc: 1.0 val_acc: 0.9155 train_loss: 0.0001 val_loss: 0.4527\n",
      "task_id: 2 Epoch #100: train_acc: 1.0 val_acc: 0.9155 train_loss: 0.0001 val_loss: 0.4528\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "task_id: 2 Epoch #110: train_acc: 1.0 val_acc: 0.9155 train_loss: 0.0001 val_loss: 0.4529\n",
      "task_id: 2 Epoch #120: train_acc: 1.0 val_acc: 0.9155 train_loss: 0.0001 val_loss: 0.4529\n",
      "Epoch   124: reducing learning rate of group 0 to 2.0000e-06.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NCScenarioLoader' object has no attribute 'initial_test_result'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5087e201a010>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                  \u001b[0mscheduler_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.001\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                  benchmark = True, seed = 42)\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_per_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/22-graph-continual/BeGin/begin/trainers/nodes.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, epoch_per_task)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_per_task\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_per_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;31m# dump the results as pickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/22-graph-continual/BeGin/begin/trainers/common.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, epoch_per_task)\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mexp_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'exp'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                         \u001b[0meval_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__scenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m                     \u001b[0;32melif\u001b[0m \u001b[0msplit\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m                         \u001b[0mbase_eval_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexp_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__scenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_accum_eval_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/22-graph-continual/BeGin/begin/scenarios/nodes.py\u001b[0m in \u001b[0;36mnext_task\u001b[0;34m(self, preds)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0maf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mscores_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tasks\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_test_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m                 \u001b[0mfwt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tasks\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tasks\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitial_test_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_tasks\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NCScenarioLoader' object has no attribute 'initial_test_result'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from begin.algorithms.bare.nodes import NCClassILBareTrainer\n",
    "from begin.scenarios.nodes import NCScenarioLoader\n",
    "from begin.utils import GCN\n",
    "scenario = NCScenarioLoader(dataset_name='cora', num_tasks=3, metric='accuracy', save_path='data', incr_type='class', task_shuffle=1)\n",
    "model = GCN(scenario.num_feats, scenario.num_classes, 256, dropout=0.0)\n",
    "benchmark = NCClassILBareTrainer(model = model,\n",
    "                                 scenario = scenario,\n",
    "                                 optimizer_fn = lambda x: torch.optim.Adam(x, lr=1e-3, weight_decay=0),\n",
    "                                 loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-1),\n",
    "                                 device = torch.device('cuda:0'),\n",
    "                                 scheduler_fn = lambda x: torch.optim.lr_scheduler.ReduceLROnPlateau(x, mode='min', patience=20, min_lr=1e-3 * 0.001 * 2., verbose=True),\n",
    "                                 benchmark = True, seed = 42)\n",
    "results = benchmark.run(epoch_per_task = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af416dda-b800-4828-b446-6c857be8f355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5bc49a2-90cd-4d3d-ac0e-6828eb9b2c42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5cff85c-9d75-43d1-8bea-b92ae4305826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_id: 0 Epoch #0: train_acc: 0.4 val_acc: 0.2651 train_loss: 0.7687 val_loss: 0.6978\n",
      "task_id: 0 Epoch #10: train_acc: 1.0 val_acc: 0.7349 train_loss: 0.0024 val_loss: 0.6477\n",
      "task_id: 0 Epoch #20: train_acc: 1.0 val_acc: 0.7395 train_loss: 0.0003 val_loss: 0.6027\n",
      "task_id: 0 Epoch #30: train_acc: 1.0 val_acc: 0.8651 train_loss: 0.0001 val_loss: 0.558\n",
      "task_id: 0 Epoch #40: train_acc: 1.0 val_acc: 0.9209 train_loss: 0.0001 val_loss: 0.5065\n",
      "task_id: 0 Epoch #50: train_acc: 1.0 val_acc: 0.9163 train_loss: 0.0001 val_loss: 0.4409\n",
      "task_id: 0 Epoch #60: train_acc: 1.0 val_acc: 0.9209 train_loss: 0.0 val_loss: 0.3724\n",
      "task_id: 0 Epoch #70: train_acc: 1.0 val_acc: 0.8791 train_loss: 0.0 val_loss: 0.3301\n",
      "task_id: 0 Epoch #80: train_acc: 1.0 val_acc: 0.8698 train_loss: 0.0 val_loss: 0.3358\n",
      "task_id: 0 Epoch #90: train_acc: 1.0 val_acc: 0.8651 train_loss: 0.0 val_loss: 0.3612\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-04.\n",
      "task_id: 0 Epoch #100: train_acc: 1.0 val_acc: 0.8837 train_loss: 0.0 val_loss: 0.3782\n",
      "task_id: 0 Epoch #110: train_acc: 1.0 val_acc: 0.8977 train_loss: 0.0 val_loss: 0.3835\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "task_id: 0 Epoch #120: train_acc: 1.0 val_acc: 0.9023 train_loss: 0.0 val_loss: 0.385\n",
      "task_id: 0 Epoch #130: train_acc: 1.0 val_acc: 0.9023 train_loss: 0.0 val_loss: 0.3856\n",
      "Epoch   137: reducing learning rate of group 0 to 2.0000e-06.\n",
      "task_id: 1 Epoch #0: train_acc: 0.25 val_acc: 0.2158 train_loss: 1.8373 val_loss: 1.3678\n",
      "task_id: 1 Epoch #10: train_acc: 1.0 val_acc: 0.9568 train_loss: 0.0059 val_loss: 0.2907\n",
      "task_id: 1 Epoch #20: train_acc: 1.0 val_acc: 0.9496 train_loss: 0.0005 val_loss: 0.1403\n",
      "task_id: 1 Epoch #30: train_acc: 1.0 val_acc: 0.9496 train_loss: 0.0002 val_loss: 0.1392\n",
      "task_id: 1 Epoch #40: train_acc: 1.0 val_acc: 0.9496 train_loss: 0.0001 val_loss: 0.1433\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "task_id: 1 Epoch #50: train_acc: 1.0 val_acc: 0.9496 train_loss: 0.0001 val_loss: 0.1438\n",
      "task_id: 1 Epoch #60: train_acc: 1.0 val_acc: 0.9496 train_loss: 0.0001 val_loss: 0.1437\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-05.\n",
      "task_id: 1 Epoch #70: train_acc: 1.0 val_acc: 0.9496 train_loss: 0.0001 val_loss: 0.1437\n",
      "task_id: 1 Epoch #80: train_acc: 1.0 val_acc: 0.9496 train_loss: 0.0001 val_loss: 0.1437\n",
      "Epoch    88: reducing learning rate of group 0 to 2.0000e-06.\n",
      "task_id: 2 Epoch #0: train_acc: 0.025 val_acc: 0.1 train_loss: 2.1336 val_loss: 1.935\n",
      "task_id: 2 Epoch #10: train_acc: 1.0 val_acc: 0.8636 train_loss: 0.0122 val_loss: 0.6061\n",
      "task_id: 2 Epoch #20: train_acc: 1.0 val_acc: 0.9545 train_loss: 0.0003 val_loss: 0.3092\n",
      "task_id: 2 Epoch #30: train_acc: 1.0 val_acc: 0.9636 train_loss: 0.0001 val_loss: 0.2294\n",
      "task_id: 2 Epoch #40: train_acc: 1.0 val_acc: 0.9545 train_loss: 0.0 val_loss: 0.2016\n",
      "task_id: 2 Epoch #50: train_acc: 1.0 val_acc: 0.9545 train_loss: 0.0 val_loss: 0.1908\n",
      "task_id: 2 Epoch #60: train_acc: 1.0 val_acc: 0.9545 train_loss: 0.0 val_loss: 0.1865\n",
      "task_id: 2 Epoch #70: train_acc: 1.0 val_acc: 0.9545 train_loss: 0.0 val_loss: 0.1848\n",
      "task_id: 2 Epoch #80: train_acc: 1.0 val_acc: 0.9545 train_loss: 0.0 val_loss: 0.1842\n",
      "task_id: 2 Epoch #90: train_acc: 1.0 val_acc: 0.9545 train_loss: 0.0 val_loss: 0.1842\n",
      "task_id: 2 Epoch #100: train_acc: 1.0 val_acc: 0.9545 train_loss: 0.0 val_loss: 0.1843\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-04.\n",
      "task_id: 2 Epoch #110: train_acc: 1.0 val_acc: 0.9545 train_loss: 0.0 val_loss: 0.1845\n",
      "task_id: 2 Epoch #120: train_acc: 1.0 val_acc: 0.9545 train_loss: 0.0 val_loss: 0.1846\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-05.\n",
      "task_id: 2 Epoch #130: train_acc: 1.0 val_acc: 0.9545 train_loss: 0.0 val_loss: 0.1846\n",
      "task_id: 2 Epoch #140: train_acc: 1.0 val_acc: 0.9545 train_loss: 0.0 val_loss: 0.1846\n",
      "Epoch   149: reducing learning rate of group 0 to 2.0000e-06.\n",
      "init_acc: [0.         0.         0.00938967 0.00220022]\n",
      "algo_acc_mat: [[0.9028436  0.         0.         0.41914192]\n",
      " [0.49289098 0.95620435 0.         0.5170517 ]\n",
      " [0.00947867 0.59489053 0.9624413  0.40924093]]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'exp_AP'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3fe36c53e985>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_per_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/22-graph-continual/BeGin/begin/trainers/nodes.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, epoch_per_task)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'init_acc:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'algo_acc_mat:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo_acc_mat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AP:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_AP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AF:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_AF'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FWT:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'exp_FWT'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'exp_AP'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538eeb2d-49b2-4aae-9d6e-3d1642c9d573",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch1.7.1_p37)",
   "language": "python",
   "name": "conda_pytorch1.7.1_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
